{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistcal Language Model Trained on Charles Dicken's A Christmas Carol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('christmascarol.txt', 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "In Prose\n\nBEING A GHOST STORY OF CHRISTMAS\n\n\n\n\nSTAVE ONE\n\nMARLEY'S GHOST\n\n\nMarley was dead, to begin with. There is no doubt whatever about that.\nThe register of his burial was signed by the clergyman, the clerk, the\nundertaker, and the chief mourner. Scrooge signed it. And Scrooge's name\nwas good u\n"
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replace ‘–‘ with a white space so we can split words better.\n",
    "* Split words based on white space.\n",
    "* Remove all punctuation from words to reduce the vocabulary size (e.g. ‘What?’ becomes ‘What’).\n",
    "* Remove all words that are not alphabetic to remove standalone punctuation tokens.\n",
    "* Normalize all words to lowercase to reduce the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "28834\n"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def staging(text):\n",
    "    text = text.replace('-', ' ')\n",
    "    tokens = text.split()\n",
    "\n",
    "    # remove punctuation from each token\n",
    "    p_map = string.punctuation.maketrans('','','.') #save fulstop\n",
    "    p_remove = string.punctuation.translate(p_map)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\t# make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokens = staging(text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of sequences to avail:  28783\n"
    }
   ],
   "source": [
    "seq_len = 51\n",
    "X = []\n",
    "\n",
    "for i in range(seq_len , len(tokens)):\n",
    "    seq = tokens[i - seq_len : i]\n",
    "    line = ' '.join(seq)\n",
    "    X.append(line)\n",
    "print(\"Number of sequences to avail: \", len(X))\n",
    "\n",
    "data = '\\n'.join(X)\n",
    "file = open('data_in.txt', 'w')\n",
    "file.write(data)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit8f1b4bc6f2ba477b8ca9980dae4c5a53",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}